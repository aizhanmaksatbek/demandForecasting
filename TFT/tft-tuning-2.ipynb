{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b525c78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T16:29:51.827235Z",
     "iopub.status.busy": "2026-01-02T16:29:51.826934Z",
     "iopub.status.idle": "2026-01-02T16:29:51.834757Z",
     "shell.execute_reply": "2026-01-02T16:29:51.834098Z"
    },
    "papermill": {
     "duration": 0.013104,
     "end_time": "2026-01-02T16:29:51.836190",
     "exception": false,
     "start_time": "2026-01-02T16:29:51.823086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "\"\"\"Configuration settings for TFT model.\"\"\"\n",
    "WORKING_DIR = \"/kaggle/input/demandforecasting/demandForecasting/\"\n",
    "# WORKING_DIR = \"\"\n",
    "TFT_CHECKPOINTS_DIR = os.path.join(\"TFT\", \"checkpoints\")\n",
    "RAW = f\"{WORKING_DIR}/data_raw/\"\n",
    "TFT_DATA_DIR = f\"{WORKING_DIR}TFT/data\"\n",
    "\n",
    "# encoder features\n",
    "ENC_VARS = [\n",
    "    \"sales\",\n",
    "    \"transactions\",\n",
    "    \"dcoilwtico\",\n",
    "    \"onpromotion\",\n",
    "    \"dow\",\n",
    "    \"month\",\n",
    "    \"weekofyear\",\n",
    "    \"is_holiday\",\n",
    "    \"is_workday\"\n",
    "]\n",
    "# known future features\n",
    "DEC_VARS = [\n",
    "    \"onpromotion\",\n",
    "    \"dow\",\n",
    "    \"month\",\n",
    "    \"weekofyear\",\n",
    "    \"is_holiday\",\n",
    "    \"is_workday\"\n",
    "]\n",
    "# static features\n",
    "STATIC_COLS = [\n",
    "    \"store_nbr\",\n",
    "    \"family\",\n",
    "    \"state\",\n",
    "    \"cluster\"\n",
    "    ]\n",
    "\n",
    "REALS_TO_SCALE = [\n",
    "    \"transactions\",\n",
    "    \"dcoilwtico\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b8389e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T16:29:51.841311Z",
     "iopub.status.busy": "2026-01-02T16:29:51.840824Z",
     "iopub.status.idle": "2026-01-02T16:29:52.011963Z",
     "shell.execute_reply": "2026-01-02T16:29:52.011003Z"
    },
    "papermill": {
     "duration": 0.175565,
     "end_time": "2026-01-02T16:29:52.013884",
     "exception": false,
     "start_time": "2026-01-02T16:29:51.838319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan  2 16:29:51 2026       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   34C    P0             25W /  250W |       0MiB /  16384MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7660921",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T16:29:52.019309Z",
     "iopub.status.busy": "2026-01-02T16:29:52.018800Z",
     "iopub.status.idle": "2026-01-02T16:30:11.958489Z",
     "shell.execute_reply": "2026-01-02T16:30:11.957629Z"
    },
    "papermill": {
     "duration": 19.944218,
     "end_time": "2026-01-02T16:30:11.960107",
     "exception": false,
     "start_time": "2026-01-02T16:29:52.015889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch CUDA available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 16:29:57.579088: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767371397.769660      25 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767371397.824926      25 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767371398.279547      25 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767371398.279608      25 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767371398.279611      25 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767371398.279613      25 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow GPU list: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow GPU list: {tf.config.list_physical_devices('GPU')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1fda9a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T16:30:11.966245Z",
     "iopub.status.busy": "2026-01-02T16:30:11.965398Z",
     "iopub.status.idle": "2026-01-02T16:30:11.969233Z",
     "shell.execute_reply": "2026-01-02T16:30:11.968544Z"
    },
    "papermill": {
     "duration": 0.008163,
     "end_time": "2026-01-02T16:30:11.970578",
     "exception": false,
     "start_time": "2026-01-02T16:30:11.962415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/kaggle/input/demandforecasting/demandForecasting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6525790c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T16:30:11.976084Z",
     "iopub.status.busy": "2026-01-02T16:30:11.975552Z",
     "iopub.status.idle": "2026-01-02T16:30:11.981040Z",
     "shell.execute_reply": "2026-01-02T16:30:11.980385Z"
    },
    "papermill": {
     "duration": 0.009752,
     "end_time": "2026-01-02T16:30:11.982391",
     "exception": false,
     "start_time": "2026-01-02T16:30:11.972639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a107dc7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T16:30:11.988232Z",
     "iopub.status.busy": "2026-01-02T16:30:11.987832Z",
     "iopub.status.idle": "2026-01-03T00:55:41.036248Z",
     "shell.execute_reply": "2026-01-03T00:55:41.035256Z"
    },
    "papermill": {
     "duration": 30329.053334,
     "end_time": "2026-01-03T00:55:41.037856",
     "exception": false,
     "start_time": "2026-01-02T16:30:11.984522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 2760318 | Val: 49896 | Test: 48114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 [train]: 100%|██████████| 10783/10783 [35:13<00:00,  5.10it/s, loss=21.4858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train Loss: 103.893941,               Train Metrics: {'mae': 216.47283935546875, 'wape': 0.6030859351158142, 'smape': 1.0205391645431519}\n",
      "Epoch 1 Validation Loss: 76.832314,               Validation Metrics: {'mae': 170.27674865722656, 'wape': 0.35288771986961365, 'smape': 0.5617756843566895}\n",
      "Saved TFT model to tft_best.pt at 1                     epochs (val_loss=76.832314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 [train]: 100%|██████████| 10783/10783 [34:40<00:00,  5.18it/s, loss=41.6034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Train Loss: 36.059187,               Train Metrics: {'mae': 90.56014251708984, 'wape': 0.2522982656955719, 'smape': 0.9193856120109558}\n",
      "Epoch 2 Validation Loss: 33.964924,               Validation Metrics: {'mae': 90.49281311035156, 'wape': 0.18754059076309204, 'smape': 0.6436980962753296}\n",
      "Saved TFT model to tft_best.pt at 2                     epochs (val_loss=33.964924)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 [train]: 100%|██████████| 10783/10783 [34:43<00:00,  5.18it/s, loss=17.5162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Train Loss: 24.003759,               Train Metrics: {'mae': 68.6312255859375, 'wape': 0.19120442867279053, 'smape': 0.9168866872787476}\n",
      "Epoch 3 Validation Loss: 27.722538,               Validation Metrics: {'mae': 78.5736083984375, 'wape': 0.16283880174160004, 'smape': 0.5497755408287048}\n",
      "Saved TFT model to tft_best.pt at 3                     epochs (val_loss=27.722538)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 [train]: 100%|██████████| 10783/10783 [35:14<00:00,  5.10it/s, loss=16.9944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Train Loss: 21.883278,               Train Metrics: {'mae': 63.77964401245117, 'wape': 0.1776883453130722, 'smape': 0.9105744361877441}\n",
      "Epoch 4 Validation Loss: 26.441577,               Validation Metrics: {'mae': 75.13134765625, 'wape': 0.15570494532585144, 'smape': 0.6119471192359924}\n",
      "Saved TFT model to tft_best.pt at 4                     epochs (val_loss=26.441577)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 [train]: 100%|██████████| 10783/10783 [35:26<00:00,  5.07it/s, loss=22.5254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Train Loss: 21.137168,               Train Metrics: {'mae': 61.76539611816406, 'wape': 0.17207714915275574, 'smape': 0.907207190990448}\n",
      "Epoch 5 Validation Loss: 26.081718,               Validation Metrics: {'mae': 74.63662719726562, 'wape': 0.15467967092990875, 'smape': 0.59743332862854}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 [train]: 100%|██████████| 10783/10783 [35:10<00:00,  5.11it/s, loss=21.0937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Train Loss: 20.606297,               Train Metrics: {'mae': 60.315086364746094, 'wape': 0.16803622245788574, 'smape': 0.90375816822052}\n",
      "Epoch 6 Validation Loss: 26.022258,               Validation Metrics: {'mae': 74.93453979492188, 'wape': 0.15529707074165344, 'smape': 0.5397894382476807}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 [train]: 100%|██████████| 10783/10783 [35:00<00:00,  5.13it/s, loss=20.9993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Train Loss: 20.274323,               Train Metrics: {'mae': 59.36318588256836, 'wape': 0.16538487374782562, 'smape': 0.9015188217163086}\n",
      "Epoch 7 Validation Loss: 25.230773,               Validation Metrics: {'mae': 72.15264129638672, 'wape': 0.149531751871109, 'smape': 0.6680188179016113}\n",
      "Saved TFT model to tft_best.pt at 7                     epochs (val_loss=25.230773)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 [train]: 100%|██████████| 10783/10783 [35:40<00:00,  5.04it/s, loss=10.8687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Train Loss: 19.929114,               Train Metrics: {'mae': 58.39336395263672, 'wape': 0.16268233954906464, 'smape': 0.8996798396110535}\n",
      "Epoch 8 Validation Loss: 25.597094,               Validation Metrics: {'mae': 73.80294799804688, 'wape': 0.1529519110918045, 'smape': 0.5599561929702759}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 [train]: 100%|██████████| 10783/10783 [35:53<00:00,  5.01it/s, loss=21.5622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Train Loss: 19.695725,               Train Metrics: {'mae': 57.7153434753418, 'wape': 0.1607932299375534, 'smape': 0.8979678750038147}\n",
      "Epoch 9 Validation Loss: 24.584762,               Validation Metrics: {'mae': 70.2391586303711, 'wape': 0.1455661952495575, 'smape': 0.6113264560699463}\n",
      "Saved TFT model to tft_best.pt at 9                     epochs (val_loss=24.584762)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 [train]: 100%|██████████| 10783/10783 [34:59<00:00,  5.14it/s, loss=20.4659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Train Loss: 19.457836,               Train Metrics: {'mae': 57.02552032470703, 'wape': 0.15887156128883362, 'smape': 0.8971431851387024}\n",
      "Epoch 10 Validation Loss: 24.907079,               Validation Metrics: {'mae': 71.48946380615234, 'wape': 0.14815737307071686, 'smape': 0.6432635188102722}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 [train]: 100%|██████████| 10783/10783 [35:20<00:00,  5.08it/s, loss=25.1889]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Train Loss: 19.261267,               Train Metrics: {'mae': 56.45172882080078, 'wape': 0.1572730988264084, 'smape': 0.8967845439910889}\n",
      "Epoch 11 Validation Loss: 24.661042,               Validation Metrics: {'mae': 70.7729721069336, 'wape': 0.14667248725891113, 'smape': 0.5381738543510437}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 [train]: 100%|██████████| 10783/10783 [35:03<00:00,  5.13it/s, loss=23.7477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Train Loss: 19.046882,               Train Metrics: {'mae': 55.85866928100586, 'wape': 0.1556205302476883, 'smape': 0.8956518173217773}\n",
      "Epoch 12 Validation Loss: 24.750305,               Validation Metrics: {'mae': 71.186279296875, 'wape': 0.14752903580665588, 'smape': 0.6136394143104553}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 [train]: 100%|██████████| 10783/10783 [35:04<00:00,  5.12it/s, loss=29.1722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Train Loss: 18.861352,               Train Metrics: {'mae': 55.32265853881836, 'wape': 0.15412776172161102, 'smape': 0.8956164717674255}\n",
      "Epoch 13 Validation Loss: 24.520793,               Validation Metrics: {'mae': 70.5121078491211, 'wape': 0.14613185822963715, 'smape': 0.6042813658714294}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 [train]: 100%|██████████| 10783/10783 [35:30<00:00,  5.06it/s, loss=14.1599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Train Loss: 18.732336,               Train Metrics: {'mae': 54.920928955078125, 'wape': 0.153008371591568, 'smape': 0.8948394060134888}\n",
      "Epoch 14 Validation Loss: 24.620863,               Validation Metrics: {'mae': 71.01564025878906, 'wape': 0.1471754014492035, 'smape': 0.6221717596054077}\n",
      "Early stopping at epoch 14 (patience=5,                    min_delta=0.5)\n",
      "Loaded stored TFT model for evaluation tft_best.pt\n",
      "Saved test forecasts CSV -> tft_test_forecasts.csv\n",
      "Test Loss: 24.662834. Test Metrics: {'mae': 70.62957763671875, 'wape': 0.14813287556171417, 'smape': 0.6175957918167114}\n",
      "Test matrics: {'mae': 70.62957763671875, 'wape': 0.14813287556171417, 'smape': 0.6175957918167114}\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from TFT.architecture.tft import TemporalFusionTransformer, QuantileLoss\n",
    "from TFT.tft_dataset import TFTWindowDataset, tft_collate\n",
    "from utils.utils import set_seed, build_onehot_maps\n",
    "from utils.utils import compute_metrics\n",
    "from utils.utils import get_date_splits\n",
    "\n",
    "\n",
    "def save_results_csv(rows):\n",
    "    if rows:\n",
    "        test_forecasts_df = (\n",
    "            pd.DataFrame(rows)\n",
    "            .sort_values([\"family\", \"store_nbr\", \"date\"])\n",
    "        )\n",
    "        out_csv = os.path.join(\"tft_test_forecasts.csv\")\n",
    "        test_forecasts_df.to_csv(out_csv, index=False)\n",
    "        print(f\"Saved test forecasts CSV -> {out_csv}\")\n",
    "\n",
    "\n",
    "def get_data_split(dec_len, enc_len, batch_size, stride):\n",
    "    # Load data\n",
    "    panel_path = os.path.join(TFT_DATA_DIR, \"panel.csv\")\n",
    "    assert os.path.exists(panel_path), (\n",
    "        \"Run data preprocessing first: \"\n",
    "        \"python src/data/preprocess_favorita.py\"\n",
    "    )\n",
    "    df = pd.read_csv(panel_path, parse_dates=[\"date\"])\n",
    "\n",
    "    # Scale continuous features (fit on train period only)\n",
    "    train_end, val_end, test_end = get_date_splits(df, dec_len)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    train_mask = df[\"date\"] <= train_end\n",
    "    df.loc[train_mask, REALS_TO_SCALE] = scaler.fit_transform(\n",
    "        df.loc[train_mask, REALS_TO_SCALE]\n",
    "    )\n",
    "    df.loc[~train_mask, REALS_TO_SCALE] = scaler.transform(\n",
    "        df.loc[~train_mask, REALS_TO_SCALE]\n",
    "    )\n",
    "\n",
    "    # One-hot maps for static features\n",
    "    static_maps = build_onehot_maps(df, STATIC_COLS)\n",
    "    static_dims = [len(static_maps[c]) for c in STATIC_COLS]\n",
    "\n",
    "    # Dataset and loaders\n",
    "    split_bounds = (train_end, val_end, test_end)\n",
    "    train_ds = TFTWindowDataset(\n",
    "        df, enc_len, dec_len, ENC_VARS, DEC_VARS, STATIC_COLS,\n",
    "        split_bounds, split=\"train\", stride=stride,\n",
    "        static_onehot_maps=static_maps,\n",
    "    )\n",
    "    val_ds = TFTWindowDataset(\n",
    "        df, enc_len, dec_len, ENC_VARS, DEC_VARS, STATIC_COLS,\n",
    "        split_bounds, split=\"val\", stride=stride,\n",
    "        static_onehot_maps=static_maps,\n",
    "    )\n",
    "    test_ds = TFTWindowDataset(\n",
    "        df, enc_len, dec_len, ENC_VARS, DEC_VARS, STATIC_COLS,\n",
    "        split_bounds, split=\"test\", stride=stride,\n",
    "        static_onehot_maps=static_maps,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=4, pin_memory=True, collate_fn=tft_collate,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=4, pin_memory=True, collate_fn=tft_collate,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=4, pin_memory=True, collate_fn=tft_collate,\n",
    "    )\n",
    "    print(\n",
    "        f\"Train samples: {len(train_ds)} | \"\n",
    "        f\"Val: {len(val_ds)} | Test: {len(test_ds)}\"\n",
    "    )\n",
    "    return (train_loader, val_loader, test_loader,\n",
    "            static_dims,\n",
    "            len(train_ds), len(val_ds), len(test_ds)\n",
    "            )\n",
    "\n",
    "\n",
    "def train_model(model, quantiles, args, train_loader, val_loader,\n",
    "                train_len, val_len\n",
    "                ):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    criterion = QuantileLoss(quantiles=quantiles)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=args.lr, weight_decay=1e-5\n",
    "    )\n",
    "    best_val = float(\"inf\")\n",
    "    best_path = os.path.join(\"tft_best.pt\")\n",
    "    median_idx = int(np.argmin([abs(q - 0.5) for q in quantiles]))\n",
    "    # Early stopping state\n",
    "    patience = int(getattr(args, \"early_stopping_patience\", 7))\n",
    "    min_delta = float(getattr(args, \"early_stopping_min_delta\", 0.0))\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_ys, train_preds = [], []\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{args.epochs} [train]\")\n",
    "        for batch in pbar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            past = batch[\"past_inputs\"].to(device)     # [B, L_enc, E]\n",
    "            future = batch[\"future_inputs\"].to(device)  # [B, L_dec, D]\n",
    "            static = batch[\"static_inputs\"].to(device)  # [B, S]\n",
    "            y = batch[\"target\"].to(device)             # [B, L_dec]\n",
    "\n",
    "            out = model(past, future, static)\n",
    "            loss = criterion(out[\"prediction\"].to(device), y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * past.size(0)\n",
    "            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "            yhat = out[\"prediction\"][..., median_idx]\n",
    "            train_ys.append(y.detach().cpu().numpy())\n",
    "            train_preds.append(yhat.detach().cpu().numpy())\n",
    "\n",
    "        train_loss /= max(train_len, 1)\n",
    "\n",
    "        metrics_train = compute_metrics(train_ys, train_preds)\n",
    "        \n",
    "        print(f\"Epoch {epoch} Train Loss: {train_loss:.6f}, \\\n",
    "              Train Metrics: {metrics_train}\"\n",
    "              )\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        valid_ys, valid_preds = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                past = batch[\"past_inputs\"].to(device)\n",
    "                future = batch[\"future_inputs\"].to(device)\n",
    "                static = batch[\"static_inputs\"].to(device)\n",
    "                y = batch[\"target\"].to(device)\n",
    "                out = model(past, future, static)\n",
    "                loss = criterion(out[\"prediction\"].to(device), y)\n",
    "                val_loss += loss.item() * past.size(0)\n",
    "\n",
    "                yhat = out[\"prediction\"][..., median_idx]\n",
    "                valid_ys.append(y.detach().cpu().numpy())\n",
    "                valid_preds.append(yhat.detach().cpu().numpy())\n",
    "\n",
    "        val_loss /= max(val_len, 1)\n",
    "        \n",
    "        metrics_val = compute_metrics(valid_ys, valid_preds)\n",
    "        print(f\"Epoch {epoch} Validation Loss: {val_loss:.6f}, \\\n",
    "              Validation Metrics: {metrics_val}\"\n",
    "              )\n",
    "        \n",
    "\n",
    "        improved = (best_val - val_loss) > min_delta\n",
    "        if improved:\n",
    "            best_val = val_loss\n",
    "            no_improve_epochs = 0\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"model_state\": model.state_dict(),\n",
    "                    \"cfg\": vars(args),\n",
    "                    \"quantiles\": quantiles,\n",
    "                },\n",
    "                best_path,\n",
    "            )\n",
    "            print(\n",
    "                f\"Saved TFT model to {best_path} at {epoch} \\\n",
    "                    epochs (val_loss={val_loss:.6f})\"\n",
    "            )\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            if no_improve_epochs >= patience:\n",
    "                print(\n",
    "                    f\"Early stopping at epoch {epoch} (patience={patience},\\\n",
    "                    min_delta={min_delta})\"\n",
    "                )\n",
    "                break\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Evaluation on test set\n",
    "def eval_loader(model, data_loader, quantiles, test_len):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    median_idx = int(np.argmin([abs(q - 0.5) for q in quantiles]))\n",
    "    # Load saved TFT model and evaluate on test set\n",
    "    best_path = os.path.join(\"tft_best.pt\")\n",
    "    if os.path.exists(best_path):\n",
    "        ckpt = torch.load(best_path, map_location=device)\n",
    "        model.load_state_dict(ckpt[\"model_state\"])\n",
    "        print(f\"Loaded stored TFT model for evaluation {best_path}\")\n",
    "    model.eval()\n",
    "\n",
    "    criterion = QuantileLoss(quantiles=quantiles)\n",
    "    rows = []\n",
    "    total_loss = 0.0\n",
    "    test_ys, test_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            past = batch[\"past_inputs\"].to(device)\n",
    "            future = batch[\"future_inputs\"].to(device)\n",
    "            static = batch[\"static_inputs\"].to(device)\n",
    "            y = batch[\"target\"].to(device)\n",
    "\n",
    "            out = model(past, future, static)\n",
    "            preds_med = out[\"prediction\"][..., median_idx]  # [B, L_dec]\n",
    "            preds = preds_med.cpu().numpy()\n",
    "            loss = criterion(out[\"prediction\"].to(device), y)\n",
    "            total_loss += loss.item() * past.size(0)\n",
    "            yhat = out[\"prediction\"][..., median_idx]\n",
    "            test_ys.append(y.detach().cpu().numpy())\n",
    "            test_preds.append(yhat.detach().cpu().numpy())\n",
    "\n",
    "            metas = batch.get(\"meta\", [])\n",
    "            for i, meta in enumerate(metas):\n",
    "                store_nbr = meta[\"store_nbr\"]\n",
    "                family = meta[\"family\"]\n",
    "                fut_dates = meta[\"future_dates\"]\n",
    "                targets = batch[\"target\"].cpu().numpy()   # [B, L_dec]\n",
    "                for d_idx, date in enumerate(fut_dates):\n",
    "                    rows.append({\n",
    "                        \"date\": pd.to_datetime(date),\n",
    "                        \"store_nbr\": store_nbr,\n",
    "                        \"family\": family,\n",
    "                        \"y_true\": float(targets[i, d_idx]),\n",
    "                        \"y_pred\": float(preds[i, d_idx]),\n",
    "                    })\n",
    "                # Append encoder history (past sales) before\n",
    "                #   forecast horizon\n",
    "                # Use the 'sales' feature from encoder inputs\n",
    "                sales_idx = ENC_VARS.index(\"sales\")\n",
    "                past_dates = meta[\"past_dates\"]\n",
    "                for d_idx, date in enumerate(past_dates):\n",
    "                    rows.append(\n",
    "                        {\n",
    "                            \"date\": pd.to_datetime(date),\n",
    "                            \"store_nbr\": store_nbr,\n",
    "                            \"family\": family,\n",
    "                            \"y_past\": float(\n",
    "                                past[i, d_idx, sales_idx].cpu()\n",
    "                                ),\n",
    "                        }\n",
    "                    )\n",
    "    save_results_csv(rows)\n",
    "    total_loss /= max(test_len, 1)\n",
    "    test_metrics = compute_metrics(test_ys, test_preds)\n",
    "    print(f\"Test Loss: {total_loss:.6f}. Test Metrics: {test_metrics}\")\n",
    "    return test_metrics\n",
    "\n",
    "\n",
    "def main_train():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--enc-len\", type=int, default=56)\n",
    "    parser.add_argument(\"--dec-len\", type=int, default=28)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=256)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=100)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "    parser.add_argument(\"--hidden-dim\", type=int, default=64)\n",
    "    parser.add_argument(\"--d-model\", type=int, default=32)\n",
    "    parser.add_argument(\"--heads\", type=int, default=2)\n",
    "    parser.add_argument(\"--lstm-hidden\", type=int, default=32)\n",
    "    parser.add_argument(\"--lstm-layers\", type=int, default=1)\n",
    "    parser.add_argument(\"--dropout\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--quantiles\", type=str, default=\"0.1,0.5,0.9\")\n",
    "    parser.add_argument(\"--stride\", type=int, default=1)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--early-stopping-patience\", type=int, default=5,\n",
    "                        help=\"Stop if no val loss improvement for N epochs\")\n",
    "    parser.add_argument(\"--early-stopping-min-delta\", type=float, default=0.5,\n",
    "                        help=\"Minimum val loss improvement to reset patience\")\n",
    "    \n",
    "    parser.add_argument(\"--train-flag\", type=bool, default=True)\n",
    "    # args = parser.parse_args()\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    set_seed(args.seed)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    os.makedirs(TFT_CHECKPOINTS_DIR, exist_ok=True)\n",
    "\n",
    "    (\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        static_dims,\n",
    "        train_len,\n",
    "        val_len,\n",
    "        test_len,\n",
    "    ) = get_data_split(\n",
    "        args.dec_len,\n",
    "        args.enc_len,\n",
    "        args.batch_size,\n",
    "        args.stride\n",
    "        )\n",
    "    \n",
    "    # Model\n",
    "    past_input_dims = [1] * len(ENC_VARS)\n",
    "    future_input_dims = [1] * len(DEC_VARS)\n",
    "    static_input_dims = static_dims\n",
    "    quantiles = [float(x) for x in args.quantiles.split(\",\")]\n",
    "\n",
    "    model = TemporalFusionTransformer(\n",
    "        static_input_dims=static_input_dims,\n",
    "        past_input_dims=past_input_dims,\n",
    "        future_input_dims=future_input_dims,\n",
    "        d_model=args.d_model,\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        n_heads=args.heads,\n",
    "        lstm_hidden_size=args.lstm_hidden,\n",
    "        lstm_layers=args.lstm_layers,\n",
    "        dropout=args.dropout,\n",
    "        num_quantiles=len(quantiles),\n",
    "    ).to(device)\n",
    "\n",
    "    # train\n",
    "    if args.train_flag:\n",
    "        train_model(model, quantiles, args,\n",
    "                    train_loader, val_loader,\n",
    "                    train_len, val_len\n",
    "                    )\n",
    "\n",
    "    test_metrics = eval_loader(model, test_loader, quantiles, test_len)\n",
    "    print(f\"Test matrics: {test_metrics}\")\n",
    "\n",
    "\n",
    "\n",
    "main_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2843cc99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T00:56:00.304793Z",
     "iopub.status.busy": "2026-01-03T00:56:00.304184Z",
     "iopub.status.idle": "2026-01-03T00:56:00.308165Z",
     "shell.execute_reply": "2026-01-03T00:56:00.307562Z"
    },
    "papermill": {
     "duration": 9.550207,
     "end_time": "2026-01-03T00:56:00.309554",
     "exception": false,
     "start_time": "2026-01-03T00:55:50.759347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip uninstall optuna -y\n",
    "# !pip install --upgrade optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1325e29d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T00:56:19.301173Z",
     "iopub.status.busy": "2026-01-03T00:56:19.300731Z",
     "iopub.status.idle": "2026-01-03T00:56:19.306460Z",
     "shell.execute_reply": "2026-01-03T00:56:19.305901Z"
    },
    "papermill": {
     "duration": 9.60892,
     "end_time": "2026-01-03T00:56:19.307712",
     "exception": false,
     "start_time": "2026-01-03T00:56:09.698792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# import subprocess\n",
    "# import argparse\n",
    "# import re\n",
    "# import json\n",
    "# import optuna\n",
    "# optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "\n",
    "# PROJECT_ROOT = \"/kaggle/input/demandforecasting/demandForecasting\"\n",
    "# # os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "# # sys.path.insert(1, '/kaggle/input/demandforecasting/demandForecasting')\n",
    "\n",
    "# def run_train_cli(hparams, fixed_epochs):\n",
    "#     \"\"\"\n",
    "#     Launch TFT/train_tft.py as a module with mapped CLI args.\n",
    "#     Parse WAPE from stdout; prefer Validation line, fallback to Test metrics.\n",
    "#     \"\"\"\n",
    "#     cmd = [\n",
    "#         sys.executable, \"-m\", \"TFT.train_tft\",\n",
    "#         \"--enc-len\", str(56),\n",
    "#         \"--dec-len\", str(28),\n",
    "#         \"--batch-size\", str(512),\n",
    "#         \"--epochs\", str(fixed_epochs),\n",
    "#         \"--lr\", str(1e-3),\n",
    "#         \"--hidden-dim\", str(hparams[\"hidden_dim\"]),\n",
    "#         \"--d-model\", str(hparams[\"d_model\"]),\n",
    "#         \"--heads\", str(hparams[\"heads\"]),\n",
    "#         \"--dropout\", str(0.1),\n",
    "#         \"--stride\", \"1\",\n",
    "#         \"--seed\", \"42\",\n",
    "#         \"--lstm-hidden\", str(hparams[\"lstm_hidden\"]),\n",
    "#         \"--lstm-layers\", str(2),\n",
    "#     ]\n",
    "#     env = os.environ.copy()\n",
    "#     env[\"PYTHONPATH\"] = PROJECT_ROOT + (os.pathsep + env.get(\"PYTHONPATH\", \"\"))\n",
    "#     proc = subprocess.run(\n",
    "#         cmd, cwd=PROJECT_ROOT, env=env, capture_output=True, text=True\n",
    "#         )\n",
    "#     if proc.returncode != 0:\n",
    "#         raise RuntimeError(\n",
    "#             f\"Training failed:\\nSTDERR:\\n{proc.stderr}\\nSTDOUT:\\n{proc.stdout}\"\n",
    "#             )\n",
    "\n",
    "#     wape = None\n",
    "#     # Parse validation print (dict) or test metrics line\n",
    "#     for line in proc.stdout.splitlines():\n",
    "#         if \"Validation\" in line and \"WAPE:\" in line:\n",
    "#             try:\n",
    "#                 wape = float(line.split(\"WAPE:\")[1].split(\"|\")[0].strip())\n",
    "#                 break\n",
    "#             except Exception:\n",
    "#                 pass\n",
    "#         if \"Test Metrics:\" in line and \"'wape':\" in line:\n",
    "#             m = re.search(r\"'wape':\\s*([0-9\\.eE+-]+)\", line)\n",
    "#             if m:\n",
    "#                 wape = float(m.group(1))\n",
    "#     if wape is None:\n",
    "#         # Last resort: scan any dict-looking line for wape\n",
    "#         for line in proc.stdout.splitlines():\n",
    "#             m = re.search(r\"'wape':\\s*([0-9\\.eE+-]+)\", line)\n",
    "#             if m:\n",
    "#                 wape = float(m.group(1))\n",
    "#                 break\n",
    "#     if wape is None:\n",
    "#         raise RuntimeError(\n",
    "#             \"Could not parse WAPE from train output.\\n\" + proc.stdout\n",
    "#             )\n",
    "#     return wape\n",
    "\n",
    "\n",
    "# def objective(trial: optuna.Trial):\n",
    "#     # Simple search space (no epoch search)\n",
    "#     hparams = {\n",
    "#         \"hidden_dim\": trial.suggest_categorical(\"hidden_dim\", [32, 64]),\n",
    "#         \"d_model\": trial.suggest_categorical(\"d_model\", [32, 128]),\n",
    "#         \"heads\": trial.suggest_categorical(\"heads\", [2, 8]),\n",
    "#         \"lstm_hidden\": trial.suggest_categorical(\"lstm_hidden\", [16, 32]),\n",
    "#     }\n",
    "#     fixed_epochs = 1\n",
    "#     wape = run_train_cli(hparams, fixed_epochs=fixed_epochs)\n",
    "#     return wape\n",
    "\n",
    "\n",
    "# def main_tuning():\n",
    "#     ap = argparse.ArgumentParser()\n",
    "#     ap.add_argument(\"--trials\", type=int, default=2)\n",
    "#     ap.add_argument(\"--study_name\", type=str, default=\"tft_tuning4\")\n",
    "#     ap.add_argument(\"--direction\", type=str, default=\"minimize\")\n",
    "#     ap.add_argument(\"--storage\", type=str, default=None,\n",
    "#                     help=\"Optuna storage log file name\")\n",
    "#     # args = ap.parse_args()\n",
    "#     args, unknown = ap.parse_known_args()\n",
    "\n",
    "#     # Create study with optional storage for persistent tracking\n",
    "#     # create a file if doesn't exist optuna_journal.log\n",
    "#     if not os.path.exists(\"optuna_journal.log\"):\n",
    "#         open(\"optuna_journal.log\", 'a').close()\n",
    "\n",
    "#     study = optuna.create_study(\n",
    "#         study_name=args.study_name,\n",
    "#         direction=args.direction,\n",
    "#         load_if_exists=False,\n",
    "#     )\n",
    "\n",
    "#     study.optimize(\n",
    "#         objective,\n",
    "#         n_trials=args.trials,\n",
    "#         gc_after_trial=True,\n",
    "#         n_jobs=5,\n",
    "#         show_progress_bar=True\n",
    "#     )\n",
    "\n",
    "#     print(\"Best WAPE:\", study.best_value)\n",
    "#     print(\"Best params:\", study.best_params)\n",
    "\n",
    "#     out_json = os.path.join(\n",
    "#         PROJECT_ROOT, \"tft_best_params.json\"\n",
    "#         )\n",
    "#     with open(out_json, \"w\") as f:\n",
    "#         json.dump(\n",
    "#             {\"best_value\": study.best_value, \"best_params\": study.best_params},\n",
    "#             f,\n",
    "#             indent=2\n",
    "#             )\n",
    "#     print(f\"Saved best params -> {out_json}\")\n",
    "\n",
    "#     # Also export full trials dataframe if pandas is available\n",
    "#     try:\n",
    "#         df = study.trials_dataframe()\n",
    "#         out_csv = os.path.join(\n",
    "#             PROJECT_ROOT, \"tuning_trials_full.csv\"\n",
    "#             )\n",
    "#         df.to_csv(out_csv, index=False)\n",
    "#         print(f\"Saved all trial results -> {out_csv}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Could not write full trials CSV: {e}\")\n",
    "\n",
    "\n",
    "# main_tuning()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNKewYgRwNNnWf/U/Ihl1Fi",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "1p6Rfw9apiQ9a1akhp3z9588CG1sQfyNH",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9111735,
     "sourceId": 14280587,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30402.885743,
   "end_time": "2026-01-03T00:56:32.064596",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-02T16:29:49.178853",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

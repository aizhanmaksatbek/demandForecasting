{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demand Classification based on forcastability of products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast accuracy strongly depends upon the product forcastability. To determine this,we apply two coefficients:\n",
    "\n",
    "* Average Demand Interval (ADI)- it measures the demand regularity in time by computing the average inerval between two demands.\n",
    "* Square of Coefficient of variation(CV^2)- it measures the variation in quantities.\n",
    "\n",
    "Based on these 2 dimensions, we can classify demand profiles into 4 categories:\n",
    "\n",
    "a) Smooth demand (ADI < 1.32 and CV² < 0.49)- The demand is regular in time and in quantity. It is therefore easy to forecast with a low forecasting error level. \n",
    "\n",
    "b) Intermittent demand (ADI >= 1.32 and CV² < 0.49)- The demand history shows very little variation in demand quantity but a high variation in the interval between two demands. Though specific forecasting methods tackle intermittent demands, the forecast error margin is higher.\n",
    "\n",
    "c) Erratic demand (ADI < 1.32 and CV² >= 0.49)-The demand has regular occurrences in time with high quantity variations. The forecast accuracy remains shaky.\n",
    "\n",
    "d) Lumpy demand (ADI >= 1.32 and CV² >= 0.49). The demand is characterized by a large variation both in quantity and time. It is actually impossible to produce a reliable forecast, no matter which forecasting tools we use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data_raw/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"sales\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['date']=pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['dayofweek']=df['date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['dayofweek'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['date']=df['date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['date']=pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficient of Variance Squared (CV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Grouping retail sku's to identify datewise sales\n",
    "\n",
    "retail_grouped= df.groupby(['family','date']).agg(total_sale=('sales','sum')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calulating average and standard deviation\n",
    "\n",
    "cv_data = retail_grouped.groupby('family').agg(average=('total_sale','mean'),\n",
    "                                                    sd=('total_sale','std')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Calculating CV_squared\n",
    "\n",
    "cv_data['cv_sqr'] = (cv_data['sd']/cv_data['average'])**2\n",
    "cv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Demand Interval (ADI) per Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prod_by_date= df.groupby(['family','date']).agg(count=('family','count')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "skus=prod_by_date.family.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Product sku's list\n",
    "\n",
    "skus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_df= pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(skus.index)):\n",
    "    a= prod_by_date[prod_by_date['family']==skus.index[i]]\n",
    "    a['previous_date']=a['date'].shift(1)\n",
    "    new_df=pd.concat([new_df,a],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_df['duration']=new_df['date']- new_df['previous_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_df['Duration']=new_df['duration'].astype(str).str.replace('days','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_df['Duration']=pd.to_numeric(new_df['Duration'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Calculating ADI\n",
    "\n",
    "ADI = new_df.groupby('family').agg(ADI = ('Duration','mean')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ADI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Cross validation\n",
    "\n",
    "adi_cv=pd.merge(ADI,cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "adi_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Defining a fuction for categorization\n",
    "\n",
    "def category(df):\n",
    "    a=0\n",
    "    \n",
    "    if((df['ADI']<=1.34) & (df['cv_sqr']<=0.49)):\n",
    "        a='Smooth'\n",
    "    if((df['ADI']>=1.34) & (df['cv_sqr']>=0.49)):  \n",
    "        a='Lumpy'\n",
    "    if((df['ADI']<1.34) & (df['cv_sqr']>0.49)):\n",
    "        a='Erratic'\n",
    "    if((df['ADI']>1.34) & (df['cv_sqr']<0.49)):\n",
    "        a='Intermittent'\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Categorizing products based on their forcastability\n",
    "\n",
    "adi_cv['category']=adi_cv.apply(category,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: Final list of sku's categorized based on their forcastability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Categorized list\n",
    "\n",
    "adi_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Visualizing the categories\n",
    "\n",
    "sns.scatterplot(x='cv_sqr',y='ADI',hue='category',data=adi_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Final category counts\n",
    "\n",
    "adi_cv.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data_raw/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total sales over a rolling window (e.g., 28 days) for each product family\n",
    "window_size = 28  # Change this to your desired window (e.g., 7 for weekly)\n",
    "\n",
    "df_sorted = df.sort_values(['family', 'date'])\n",
    "df_sorted['date'] = pd.to_datetime(df_sorted['date'])\n",
    "df_sorted['year'] = df_sorted['date'].dt.year\n",
    "df_sorted['month'] = df_sorted['date'].dt.month\n",
    "\n",
    "# Calculate rolling sum and assign to a new column\n",
    "df_sorted['rolling_sales'] = (\n",
    "    df_sorted.groupby(\"family\")['sales']\n",
    "    .rolling(window_size)\n",
    "    .sum()\n",
    "    .shift(window_size)\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "# Plot rolling sales for each product family\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "families = df_sorted['family'].unique()\n",
    "num_families = len(families)\n",
    "ncols = 5\n",
    "nrows = (num_families + ncols - 1) // ncols\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(20, 4 * nrows), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, fam in enumerate(families):\n",
    "    fam_data = df_sorted[df_sorted['family'] == fam]\n",
    "    axes[idx].plot(fam_data['date'], fam_data['rolling_sales'], label='Rolling Sales', color='tab:blue')\n",
    "    axes[idx].set_title(f'Family: {fam}')\n",
    "    axes[idx].set_ylabel('Rolling Sales')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(idx + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"28-Day Rolling Sales by Product Family\", fontsize=18, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "window_size = 28  # or 7 for weekly\n",
    "\n",
    "df_sorted = df.sort_values(['family', 'date'])\n",
    "df_sorted['date'] = pd.to_datetime(df_sorted['date'])\n",
    "df_sorted['year'] = df_sorted['date'].dt.year\n",
    "\n",
    "# Calculate rolling sum and assign to a new column\n",
    "df_sorted['rolling_sales'] = (\n",
    "    df_sorted.groupby(\"family\")['sales']\n",
    "    .rolling(window_size)\n",
    "    .sum()\n",
    "    .shift(window_size)\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "# Aggregate rolling sales by year for each family\n",
    "yearly_rolling = (\n",
    "    df_sorted.groupby(['family', 'year'])['rolling_sales']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig = px.line(\n",
    "    yearly_rolling,\n",
    "    x=\"year\",\n",
    "    y=\"rolling_sales\",\n",
    "    color=\"family\",\n",
    "    title=\"Yearly Rolling Sales by Family\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "window_size = 28  # or 7 for weekly\n",
    "\n",
    "df_sorted = df.sort_values(['family', 'date'])\n",
    "df_sorted['date'] = pd.to_datetime(df_sorted['date'])\n",
    "df_sorted['month'] = df_sorted['date'].dt.to_period('M')\n",
    "\n",
    "# Calculate rolling sum and assign to a new column\n",
    "df_sorted['rolling_sales'] = (\n",
    "    df_sorted.groupby(\"family\")['sales']\n",
    "    .rolling(window_size)\n",
    "    .sum()\n",
    "    .shift(window_size)\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig = px.line(\n",
    "    df_sorted,\n",
    "    x=\"date\",\n",
    "    y=\"rolling_sales\",\n",
    "    color=\"family\",\n",
    "    title=\"Monthly Rolling Sales by Family\"\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1143632,
     "sourceId": 1917777,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30066,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv_demand",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
